{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We need older numpy version, otherwise an error occurs (newer numpy has no member \"int\", \"float\",...)\n",
        "# %pip install opencv-python numpy==1.23.5 openmim torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPbCuq5wWL38",
        "outputId": "6f5aad38-9292-4381-a9ed-d9f9cdeab69b"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import cv2\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import pickle\n",
        "import traceback\n",
        "from time import time\n",
        "from copy import deepcopy\n",
        "\n",
        "# Classes are defined in process_dataset/common.py\n",
        "from process_dataset.common import classes, classes_dict, datasets_path, dataset_pickle_filepath, split_datasets_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Additional paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwfR63Ryv1y2",
        "outputId": "2565aac0-e2fd-4e65-e546-2273187453a3"
      },
      "outputs": [],
      "source": [
        "import paths\n",
        "\n",
        "# Print paths.py file\n",
        "with open(\"./paths.py\") as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines.copy():\n",
        "        if line.startswith(\"#\"):\n",
        "            lines.remove(line)\n",
        "    print(\"\".join(lines).replace(\"\\n\\n\\n\", \"\\n\"))\n",
        "\n",
        "# !mkdir -p $working_dirpath\n",
        "\n",
        "# ! Do this in a separate terminal:\n",
        "# !mkdir -p $drive_dirpath\n",
        "# !rclone mount remote: $drive_dirpath\n",
        "# Don't forget to unmount when you're finished\n",
        "\n",
        "# TODO assert everything is in the right place\n",
        "assert os.path.exists(paths.proj_path)\n",
        "assert os.path.exists(paths.process_dataset_dirpath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkjCldfKpI-O"
      },
      "source": [
        "# Installing mmdetection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzbBwCKrpUQh",
        "outputId": "8f83fd26-9409-4ea9-e167-4a56efa7f260"
      },
      "outputs": [],
      "source": [
        "# We install older mmcv version, otherwise error occurs (mmdet says newest possible is 1.7.0)\n",
        "# !mim install mmcv-full==1.7.0\n",
        "# %cd $paths.mmdetection_path/..\n",
        "# !git clone https://github.com/open-mmlab/mmdetection.git\n",
        "# %cd mmdetection\n",
        "# %pip install -e .\n",
        "# %cd $paths.proj_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTcJbMQ6rfrY",
        "outputId": "116dfc55-23bf-4c06-e7a5-140a494ec630"
      },
      "outputs": [],
      "source": [
        "#@title Verify installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1vbw2orvzmF",
        "outputId": "c2ad7f29-47e0-48f1-d452-f6f1018215b3"
      },
      "outputs": [],
      "source": [
        "from mmcv import collect_env\n",
        "try:\n",
        "    collect_env() # TODO throws error\n",
        "except Exception as e:\n",
        "    print(\"Could not run 'collect_env()'. Exception:\")\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXZZKxllra7-"
      },
      "source": [
        "# Download YOLOX-s config and checkpoint (pre-trained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmd-1lfprZKZ",
        "outputId": "a1a7c23d-742f-4d5f-e274-4d743494804a"
      },
      "outputs": [],
      "source": [
        "# TODO don't download it here. Leave it to the user\n",
        "# Memory requirements for YOLOX models: \n",
        "# YOLOX-s\t7.6 GB\n",
        "# YOLOX-l\t19.9 GB\n",
        "# YOLOX-x\t28.1 GB\n",
        "\n",
        "# url = \"https://download.openmmlab.com/mmdetection/v2.0/yolox/yolox_x_8x8_300e_coco/\" + model_checkpoint_filename\n",
        "# url = \"https://download.openmmlab.com/mmdetection/v2.0/yolox/yolox_s_8x8_300e_coco/\" + paths.model_checkpoint_filename\n",
        "# !wget -c $url -O $paths.model_checkpoint_filepath\n",
        "\n",
        "assert os.path.exists(paths.model_config_filepath)\n",
        "assert os.path.exists(paths.model_checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egmFK4r_CiHB"
      },
      "outputs": [],
      "source": [
        "# https://colab.research.google.com/github/ZwwWayne/mmdetection/blob/update-colab/demo/MMDet_Tutorial.ipynb#scrollTo=hamZrlnH-YDD\n",
        "from mmdet.apis import set_random_seed\n",
        "from mmcv import Config\n",
        "\n",
        "cfg = Config.fromfile(paths.model_config_filepath)\n",
        "\n",
        "if paths.last_checkpoint_filepath:\n",
        "    cfg.resume_from = paths.last_checkpoint_filepath\n",
        "else:\n",
        "    cfg.load_from = paths.model_checkpoint_filepath\n",
        "\n",
        "cfg.work_dir = paths.working_dirpath\n",
        "\n",
        "cfg.data_root = datasets_path\n",
        "\n",
        "img_prefix = datasets_path\n",
        "\n",
        "dataset_filepath = os.path.join(datasets_path, \"dataset.pickle\")\n",
        "train_filepath = os.path.join(datasets_path, \"train.pickle\")\n",
        "val_filepath = os.path.join(datasets_path, \"val.pickle\")\n",
        "test_filepath = os.path.join(datasets_path, \"test.pickle\")\n",
        "\n",
        "# Not needed\n",
        "# img_norm_cfg = {\n",
        "#     # \"mean\": [103.530, 116.280, 123.675], # Taken from yolof\n",
        "#     \"mean\": [114.0, 114.0, 114.0], \n",
        "#     \"std\": [1.0, 1.0, 1.0], \n",
        "#     \"to_rgb\": False\n",
        "# }\n",
        "\n",
        "# Like this, we can use different augmentations for each dataset\n",
        "# + Mosaic? Probably not very useful here\n",
        "# + MixUp? Doesn't seem useful either\n",
        "per_dataset_train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations', with_bbox=True),\n",
        "    dict(type='Resize',\n",
        "        img_scale=cfg.img_scale,\n",
        "        keep_ratio=True),\n",
        "    dict(type='Pad',\n",
        "        pad_to_square=True,\n",
        "        pad_val=dict(img=(114.0, 114.0, 114.0))),\n",
        "    dict(type='RandomAffine',\n",
        "        # min_bbox_size=8, # No need. Done in FilterAnnotations\n",
        "        # border=(-cfg.img_scale[0] // 2, -cfg.img_scale[1] // 2), # This was a problem. No idea why I added it. Shouldn't exist\n",
        "        scaling_ratio_range=(0, 0), # Needs to be adjusted per dataset later below\n",
        "        max_rotate_degree=10,\n",
        "        max_shear_degree=5),\n",
        "]\n",
        "\n",
        "train_datasets_scaling_ratios = {\n",
        "    \"mio-tcd\"     : (0.7, 1.1),\n",
        "    \"aau\"         : (0.8, 1.1),\n",
        "    \"ndis\"        : (0.9, 3),\n",
        "    \"mtid\"        : (0.9, 2),\n",
        "    \"visdrone_det\": (1.5, 3),\n",
        "    \"detrac\"      : (0.8, 1.2)\n",
        "}\n",
        "\n",
        "train_pipeline = [\n",
        "    dict(type='YOLOXHSVRandomAug'),\n",
        "    dict(type='RandomFlip',\n",
        "         flip_ratio=0.5,\n",
        "         direction=\"horizontal\"), # (horizontal is implicit)\n",
        "    dict(type='FilterAnnotations',\n",
        "        min_gt_bbox_wh=(8, 8), # Should be okay but I can try increasing\n",
        "        # min_gt_bbox_wh=(16, 16), # Tried that but I think it causes small objects\n",
        "        # to be undetected (even objs of size about 32x32)\n",
        "        keep_empty=False),\n",
        "    dict(type=\"PhotoMetricDistortion\"),\n",
        "    #  Is this OK? Heard that YOLOX does not need normalization or something...\n",
        "    #  Nope, it definitely does not. I tried one epoch with and one without, and\n",
        "    #  the results (loss plots) were actually the same\n",
        "    # dict(type='Normalize', **img_norm_cfg), # img_norm_cfg taken from yolof\n",
        "    dict(type='DefaultFormatBundle'),\n",
        "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
        "]\n",
        "\n",
        "train_datasets_repeats = {\n",
        "    \"mio-tcd\"     : 1,\n",
        "    \"aau\"         : 3, # There are some misannotations so don't make it too frequent\n",
        "    \"ndis\"        : 25,\n",
        "    \"mtid\"        : 6, # It's a video, so already a lot repeats, but it's a great dataset\n",
        "    \"visdrone_det\": 4, # Good dataset, but not very important in this project\n",
        "    \"detrac\"      : 2\n",
        "}\n",
        "\n",
        "train_datasets = []\n",
        "for dataset_name in list(train_datasets_repeats.keys()):\n",
        "    ds = dict(\n",
        "        type = \"RepeatDataset\",\n",
        "        times = train_datasets_repeats[dataset_name],\n",
        "        dataset = dict(\n",
        "            type = \"CustomDataset\",\n",
        "            ann_file = os.path.join(split_datasets_path, f\"{dataset_name}_train.pickle\"),\n",
        "            img_prefix = img_prefix,\n",
        "            pipeline = deepcopy(per_dataset_train_pipeline),\n",
        "            filter_empty_gt=False\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Set RandomAffine scaling range individually for each dataset\n",
        "    assert ds[\"dataset\"][\"pipeline\"][4][\"type\"] == \"RandomAffine\"\n",
        "    ds[\"dataset\"][\"pipeline\"][4][\"scaling_ratio_range\"] = train_datasets_scaling_ratios[dataset_name]\n",
        "\n",
        "    train_datasets.append(ds)\n",
        "\n",
        "cfg.data = dict(\n",
        "    # Batch size (default 8)\n",
        "    # samples_per_gpu = 8, # Default\n",
        "    # samples_per_gpu = 32, # Let's try 32 - nope, cuda out of memory on 7400\n",
        "    # samples_per_gpu = 16, # nope, cuda out of memory on 7400\n",
        "    # samples_per_gpu = 12, # This seems to work (11111 of 11178MiB used) - not on P52\n",
        "    samples_per_gpu = 11, # Works on P52\n",
        "\n",
        "    # Workers per gpu (default 4)\n",
        "    # Tested 8, 12 and 16 on P52 and higher numbers actually made the training (ETA) longer\n",
        "    # With 12, ETA was about 10% longer than at default. Using 2, speed is slightly improved (~2%)\n",
        "    # workers_per_gpu = 4, # Default\n",
        "    # workers_per_gpu = 8, # Doesn't seem to do much\n",
        "    workers_per_gpu = 2,\n",
        "\n",
        "    persistent_workers = True,\n",
        "\n",
        "    train = dict(\n",
        "        # Tried removing MultiImageMixDataset and using ClassBalancedDataset\n",
        "        # directly, but got an error about tensor sizes\n",
        "        type = \"MultiImageMixDataset\",\n",
        "        dataset = dict(\n",
        "            type = 'ClassBalancedDataset',\n",
        "            # oversample_thr = 1e-3, # Default\n",
        "            oversample_thr = 0.1, # Seems good\n",
        "            dataset = dict(\n",
        "                type = \"ConcatDataset\",\n",
        "                datasets = train_datasets,\n",
        "                separate_eval = False\n",
        "            )\n",
        "        ),\n",
        "        pipeline = train_pipeline,\n",
        "    ),\n",
        "\n",
        "    val = dict(\n",
        "        type = \"CustomDataset\",\n",
        "        ann_file = val_filepath,\n",
        "        img_prefix = img_prefix,\n",
        "        pipeline = cfg.data.val.pipeline,\n",
        "    ),\n",
        "\n",
        "    test = dict(\n",
        "        type = \"CustomDataset\",\n",
        "        ann_file = test_filepath,\n",
        "        img_prefix = img_prefix,\n",
        "        pipeline = cfg.data.test.pipeline,\n",
        "    ),\n",
        ")\n",
        "\n",
        "cfg.gpu_ids = [0]\n",
        "cfg.device = \"cuda\"\n",
        "\n",
        "cfg.seed = int(time())\n",
        "set_random_seed(int(time()), deterministic=False)\n",
        "\n",
        "# The original learning rate (LR) is set for 8-GPU training.\n",
        "# We divide it by 8 since we only use one GPU.\n",
        "# cfg.optimizer.lr = 0.02 # This instead of 0.02 / 8 - nope, that's too much\n",
        "# cfg.optimizer.lr = 0.001 # Not better than 0.00125\n",
        "cfg.optimizer.lr /= 8 # 0.00125 # As seen on the internet, seems to be good\n",
        "\n",
        "\n",
        "# Orig yolox-s config says: USER SHOULD NOT CHANGE ITS VALUES\n",
        "# ! But that, hopefully, means that user should not change LR, but can change\n",
        "# the auto_scale_lr setting...\n",
        "# cfg.auto_scale_lr = {}\n",
        "cfg.auto_scale_lr = {\n",
        "    \"enable\": True, \n",
        "    \"base_batch_size\": cfg.data.samples_per_gpu\n",
        "    }\n",
        "\n",
        "# cfg.log_config.interval = 100\n",
        "cfg.log_config.interval = 50\n",
        "\n",
        "# Change the evaluation metric since we use customized dataset.\n",
        "cfg.evaluation.metric = 'mAP'\n",
        "\n",
        "# We can set the evaluation interval to reduce the evaluation times\n",
        "cfg.evaluation.interval = 1\n",
        "\n",
        "# We can set the checkpoint saving interval to reduce the storage cost\n",
        "cfg.checkpoint_config.interval = 1\n",
        "\n",
        "cfg.max_epochs = 300\n",
        "cfg.runner = dict(type='EpochBasedRunner', max_epochs=cfg.max_epochs)\n",
        "\n",
        "# We can also use tensorboard to log the training process\n",
        "cfg.log_config.hooks = [\n",
        "    dict(type='TextLoggerHook'),\n",
        "    dict(type='TensorboardLoggerHook')]\n",
        "\n",
        "# TODO validation sometimes\n",
        "# cfg.workflow = [('train', 1), ('val', 1)]\n",
        "\n",
        "# Removing useless keys so they don't confuse\n",
        "cfg.pop(\"train_dataset\")\n",
        "cfg.pop(\"train_pipeline\")\n",
        "cfg.pop(\"test_pipeline\")\n",
        "cfg.pop(\"dataset_type\")\n",
        "\n",
        "# Set number of classes\n",
        "cfg.model.bbox_head.num_classes = len(classes)\n",
        "\n",
        "# Tried this but it didn't help with the mmdetection's concat problem\n",
        "# cfg.data.train.dataset[\"filter_empty_gt\"] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZSc7wQWEdLp"
      },
      "outputs": [],
      "source": [
        "# https://colab.research.google.com/github/ZwwWayne/mmdetection/blob/update-colab/demo/MMDet_Tutorial.ipynb#scrollTo=hamZrlnH-YDD\n",
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "\n",
        "# Build dataset\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        " \n",
        "# Build the detector\n",
        "# model = build_detector(cfg.model, test_cfg=cfg.data.test)\n",
        "model = build_detector(cfg.model)\n",
        "\n",
        "# Train\n",
        "model.CLASSES = classes\n",
        "train_detector(model, datasets, cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from mmdet.apis import single_gpu_test\n",
        "# from mmdet.datasets import build_dataloader, build_dataset\n",
        "# from mmdet.utils import build_dp\n",
        "\n",
        "# data_loader = build_dataloader(build_dataset(cfg.data.test), samples_per_gpu=64, workers_per_gpu=1)\n",
        "# dp = build_dp(model, cfg.device, device_ids=cfg.gpu_ids)\n",
        "# outputs = single_gpu_test(dp, data_loader, out_dir=paths.working_dirpath)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "229fedebb1d7394cf57a31acf727fae7ea6323c87170158d2b4890534347897d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
