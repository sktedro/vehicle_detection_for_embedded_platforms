{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPbCuq5wWL38",
        "outputId": "6f5aad38-9292-4381-a9ed-d9f9cdeab69b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: opencv-python in /home/tedro/.local/lib/python3.9/site-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy in /home/tedro/.local/lib/python3.9/site-packages (1.23.4)\n",
            "Requirement already satisfied: openmim in /home/tedro/.local/lib/python3.9/site-packages (0.3.2)\n",
            "Requirement already satisfied: torchvision in /home/tedro/.local/lib/python3.9/site-packages (0.14.0)\n",
            "Requirement already satisfied: model-index in /home/tedro/.local/lib/python3.9/site-packages (from openmim) (0.1.11)\n",
            "Requirement already satisfied: colorama in /usr/lib/python3/dist-packages (from openmim) (0.4.4)\n",
            "Requirement already satisfied: Click in /usr/lib/python3/dist-packages (from openmim) (7.1.2)\n",
            "Requirement already satisfied: rich in /home/tedro/.local/lib/python3.9/site-packages (from openmim) (12.6.0)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from openmim) (2.25.1)\n",
            "Requirement already satisfied: pandas in /home/tedro/.local/lib/python3.9/site-packages (from openmim) (1.5.1)\n",
            "Requirement already satisfied: pip>=19.3 in /home/tedro/.local/lib/python3.9/site-packages (from openmim) (22.3.1)\n",
            "Requirement already satisfied: tabulate in /home/tedro/.local/lib/python3.9/site-packages (from openmim) (0.9.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (8.1.2)\n",
            "Requirement already satisfied: torch==1.13.0 in /home/tedro/.local/lib/python3.9/site-packages (from torchvision) (1.13.0)\n",
            "Requirement already satisfied: typing-extensions in /home/tedro/.local/lib/python3.9/site-packages (from torchvision) (4.4.0)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/tedro/.local/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/tedro/.local/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/tedro/.local/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/tedro/.local/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.7.99)\n",
            "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (0.34.2)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (52.0.0)\n",
            "Requirement already satisfied: markdown in /usr/lib/python3/dist-packages (from model-index->openmim) (3.3.4)\n",
            "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from model-index->openmim) (5.3.1)\n",
            "Requirement already satisfied: ordered-set in /home/tedro/.local/lib/python3.9/site-packages (from model-index->openmim) (4.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /home/tedro/.local/lib/python3.9/site-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->openmim) (2021.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /home/tedro/.local/lib/python3.9/site-packages (from rich->openmim) (2.13.0)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /home/tedro/.local/lib/python3.9/site-packages (from rich->openmim) (0.9.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/tedro/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->openmim) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install opencv-python numpy openmim torchvision\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import cv2\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import pickle\n",
        "\n",
        "# Classes are defined in process_dataset/common.py\n",
        "from process_dataset.common import classes, classes_dict, datasets_path, dataset_pickle_filepath"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Additional paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwfR63Ryv1y2",
        "outputId": "2565aac0-e2fd-4e65-e546-2273187453a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "import os\n",
            "\n",
            "proj_path = os.getcwd()\n",
            "\n",
            "drive_dirpath = os.path.join(proj_path, \"drive\")\n",
            "drive_traffic_cams_path = os.path.join(drive_dirpath, \"traffic_cams\")\n",
            "\n",
            "mmdetection_path = os.path.join(proj_path, \"..\", \"mmdetection\")\n",
            "\n",
            "working_dirpath = os.path.join(proj_path, \"working_dir\")\n",
            "\n",
            "process_dataset_dirpath = os.path.join(proj_path, \"process_dataset\")\n",
            "\n",
            "\n",
            "mmdetection_config_path = os.path.join(mmdetection_path, \"configs\")\n",
            "mmdetection_checkpoint_path = os.path.join(mmdetection_path, \"checkpoints\")\n",
            "\n",
            "# model_config_filename = \"yolox_x_8x8_300e_coco.py\"\n",
            "# model_config_filename = \"yolox_s_8x8_300e_coco.py\"\n",
            "model_config_filename = \"yolox_s_8x8_300e_coco_custom.py\"\n",
            "model_config_filepath = os.path.join(mmdetection_config_path, \"yolox\", model_config_filename)\n",
            "\n",
            "# And YOLOX-x checkpoint\n",
            "# model_checkpoint_filename = \"yolox_x_8x8_300e_coco_20211126_140254-1ef88d67.pth\"\n",
            "model_checkpoint_filename = \"yolox_s_8x8_300e_coco_20211121_095711-4592a793.pth\"\n",
            "model_checkpoint_filepath = os.path.join(mmdetection_path, \"checkpoints\", model_checkpoint_filename)\n",
            "if not os.path.exists(mmdetection_checkpoint_path):\n",
            "    os.mkdir(mmdetection_checkpoint_path)\n",
            "\n",
            "\n",
            "last_checkpoint_filepath = os.path.join(working_dirpath, \"latest.pth\")\n",
            "if not os.path.exists(last_checkpoint_filepath):\n",
            "    last_checkpoint_filepath = None\n",
            "\n",
            "saved_model_filepath = os.path.join(working_dirpath, 'model.pickle')\n",
            "saved_config_filepath = os.path.join(working_dirpath, 'config.pickle')\n"
          ]
        }
      ],
      "source": [
        "import paths\n",
        "\n",
        "with open(\"./paths.py\") as f:\n",
        "    print(f.read())\n",
        "\n",
        "# proj_path = os.getcwd()\n",
        "\n",
        "# drive_dirpath = os.path.join(proj_path, \"drive\")\n",
        "# drive_traffic_cams_path = os.path.join(drive_dirpath, \"traffic_cams\")\n",
        "\n",
        "# mmdetection_path = os.path.join(proj_path, \"..\", \"mmdetection\")\n",
        "\n",
        "# working_dirpath = os.path.join(proj_path, \"working_dir\")\n",
        "\n",
        "# process_dataset_dirpath = os.path.join(proj_path, \"process_dataset\")\n",
        "\n",
        "# !mkdir -p $working_dirpath\n",
        "\n",
        "# ! Do this in a separate terminal:\n",
        "# !mkdir -p $drive_dirpath\n",
        "# !rclone mount remote: $drive_dirpath\n",
        "\n",
        "# Don't forget to unmount when you're finished\n",
        "\n",
        "# TODO assert everything is in the right place"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkjCldfKpI-O"
      },
      "source": [
        "# Installing mmdetection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzbBwCKrpUQh",
        "outputId": "8f83fd26-9409-4ea9-e167-4a56efa7f260"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: mim: command not found\n",
            "/home/tedro/Desktop/d_projekty/bp\n",
            "fatal: destination path 'mmdetection' already exists and is not an empty directory.\n",
            "/home/tedro/Desktop/d_projekty/bp/mmdetection\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Obtaining file:///home/tedro/Desktop/d_projekty/bp/mmdetection\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (from mmdet==2.25.3) (3.3.4)\n",
            "Requirement already satisfied: numpy in /home/tedro/.local/lib/python3.9/site-packages (from mmdet==2.25.3) (1.23.4)\n",
            "Requirement already satisfied: pycocotools in /home/tedro/.local/lib/python3.9/site-packages (from mmdet==2.25.3) (2.0.5)\n",
            "Requirement already satisfied: six in /home/tedro/.local/lib/python3.9/site-packages (from mmdet==2.25.3) (1.16.0)\n",
            "Requirement already satisfied: terminaltables in /home/tedro/.local/lib/python3.9/site-packages (from mmdet==2.25.3) (3.1.10)\n",
            "Installing collected packages: mmdet\n",
            "  Attempting uninstall: mmdet\n",
            "    Found existing installation: mmdet 2.25.3\n",
            "    Uninstalling mmdet-2.25.3:\n",
            "      Successfully uninstalled mmdet-2.25.3\n",
            "  Running setup.py develop for mmdet\n",
            "Successfully installed mmdet\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "/home/tedro/Desktop/d_projekty/bp/proj\n"
          ]
        }
      ],
      "source": [
        "!mim install mmcv-full\n",
        "%cd $paths.mmdetection_path/..\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd mmdetection\n",
        "%pip install -e .\n",
        "%cd $paths.proj_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTcJbMQ6rfrY",
        "outputId": "116dfc55-23bf-4c06-e7a5-140a494ec630"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tedro/.local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.25.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tedro/.local/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#@title Verify installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1vbw2orvzmF",
        "outputId": "c2ad7f29-47e0-48f1-d452-f6f1018215b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sys.platform': 'linux',\n",
              " 'Python': '3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110]',\n",
              " 'CUDA available': True,\n",
              " 'GPU 0': 'NVIDIA GeForce GTX 1080 Ti',\n",
              " 'CUDA_HOME': '/usr/local/cuda',\n",
              " 'NVCC': 'Cuda compilation tools, release 11.8, V11.8.89',\n",
              " 'GCC': 'x86_64-linux-gnu-gcc (Debian 10.2.1-6) 10.2.1 20210110',\n",
              " 'PyTorch': '1.13.0+cu117',\n",
              " 'PyTorch compiling details': 'PyTorch built with:\\n  - GCC 9.3\\n  - C++ Version: 201402\\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\\n  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\\n  - LAPACK is enabled (usually provided by MKL)\\n  - NNPACK is enabled\\n  - CPU capability usage: AVX2\\n  - CUDA Runtime 11.7\\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\\n  - CuDNN 8.5\\n  - Magma 2.6.1\\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \\n',\n",
              " 'TorchVision': '0.14.0+cu117',\n",
              " 'OpenCV': '4.6.0',\n",
              " 'MMCV': '1.7.0',\n",
              " 'MMCV Compiler': 'GCC 10.2',\n",
              " 'MMCV CUDA Compiler': '11.8'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mmcv import collect_env\n",
        "collect_env()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXZZKxllra7-"
      },
      "source": [
        "# Download YOLOX-s config and checkpoint (pre-trained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmd-1lfprZKZ",
        "outputId": "a1a7c23d-742f-4d5f-e274-4d743494804a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-11-28 13:26:56--  https://download.openmmlab.com/mmdetection/v2.0/yolox/yolox_s_8x8_300e_coco/yolox_s_8x8_300e_coco_20211121_095711-4592a793.pth\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 47.254.186.218\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|47.254.186.218|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Memory requirements for YOLOX models: \n",
        "# YOLOX-s\t7.6 GB\n",
        "# YOLOX-l\t19.9 GB\n",
        "# YOLOX-x\t28.1 GB\n",
        "\n",
        "# url = \"https://download.openmmlab.com/mmdetection/v2.0/yolox/yolox_x_8x8_300e_coco/\" + model_checkpoint_filename\n",
        "url = \"https://download.openmmlab.com/mmdetection/v2.0/yolox/yolox_s_8x8_300e_coco/\" + paths.model_checkpoint_filename\n",
        "!wget -c $url -O $paths.model_checkpoint_filepath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "egmFK4r_CiHB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'type': 'LoadImageFromFile'},\n",
              " {'type': 'MultiScaleFlipAug',\n",
              "  'img_scale': (640, 640),\n",
              "  'flip': False,\n",
              "  'transforms': [{'type': 'Resize', 'keep_ratio': True},\n",
              "   {'type': 'RandomFlip'},\n",
              "   {'type': 'Pad',\n",
              "    'pad_to_square': True,\n",
              "    'pad_val': {'img': (114.0, 114.0, 114.0)}},\n",
              "   {'type': 'DefaultFormatBundle'},\n",
              "   {'type': 'Collect', 'keys': ['img']}]}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# https://colab.research.google.com/github/ZwwWayne/mmdetection/blob/update-colab/demo/MMDet_Tutorial.ipynb#scrollTo=hamZrlnH-YDD\n",
        "from mmdet.apis import set_random_seed\n",
        "from mmcv import Config\n",
        "\n",
        "cfg = Config.fromfile(paths.model_config_filepath)\n",
        "\n",
        "# print(f'Initial config:\\n{cfg.pretty_text}')\n",
        "\n",
        "if paths.last_checkpoint_filepath:\n",
        "    cfg.resume_from = paths.last_checkpoint_filepath\n",
        "else:\n",
        "    cfg.load_from = paths.model_checkpoint_filepath\n",
        "\n",
        "cfg.work_dir = paths.working_dirpath\n",
        "\n",
        "# cfg.data_root = dataset_mio_tcd_path\n",
        "cfg.data_root = datasets_path\n",
        "\n",
        "# cfg.dataset_type = \"CustomDataset\"\n",
        "\n",
        "# img_prefix = dataset_mio_tcd_path\n",
        "img_prefix = datasets_path\n",
        "\n",
        "# dataset_filepath = os.path.join(dataset_mio_tcd_path, \"gt.pickle\")\n",
        "dataset_filepath = os.path.join(datasets_path, \"dataset.pickle\")\n",
        "train_filepath = os.path.join(datasets_path, \"train.pickle\")\n",
        "val_filepath = os.path.join(datasets_path, \"val.pickle\")\n",
        "test_filepath = os.path.join(datasets_path, \"test.pickle\")\n",
        "\n",
        "# cfg.train_dataset.dataset.type = \"CustomDataset\"\n",
        "# cfg.train_dataset.dataset.ann_file = train_filepath\n",
        "# cfg.train_dataset.dataset.img_prefix = img_prefix\n",
        "cfg.data.train.dataset.type = \"CustomDataset\"\n",
        "cfg.data.train.dataset.ann_file = train_filepath\n",
        "cfg.data.train.dataset.img_prefix = img_prefix\n",
        "cfg.data.val.type = \"CustomDataset\"\n",
        "cfg.data.val.ann_file = val_filepath\n",
        "cfg.data.val.img_prefix = img_prefix\n",
        "cfg.data.test.type = \"CustomDataset\"\n",
        "cfg.data.test.ann_file = test_filepath\n",
        "cfg.data.test.img_prefix = img_prefix\n",
        "\n",
        "# TODO try class balanced\n",
        "cfg.data.train.dataset = {\n",
        "        \"type\": 'ClassBalancedDataset',\n",
        "        # \"oversample_thr\": 1e-3,\n",
        "        \"oversample_thr\": 0.2,\n",
        "        \"dataset\": cfg.data.train.dataset\n",
        "    }\n",
        "\n",
        "cfg.gpu_ids = [0]\n",
        "cfg.device = \"cuda\"\n",
        "\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "\n",
        "# The original learning rate (LR) is set for 8-GPU training.\n",
        "# We divide it by 8 since we only use one GPU.\n",
        "# cfg.optimizer.lr = 0.02 / 8\n",
        "cfg.lr_config.warmup = None\n",
        "\n",
        "cfg.log_config.interval = 50\n",
        "\n",
        "# Change the evaluation metric since we use customized dataset.\n",
        "cfg.evaluation.metric = 'mAP'\n",
        "\n",
        "# We can set the evaluation interval to reduce the evaluation times\n",
        "cfg.evaluation.interval = 1\n",
        "\n",
        "# We can set the checkpoint saving interval to reduce the storage cost\n",
        "cfg.checkpoint_config.interval = 1\n",
        "\n",
        "cfg.max_epochs = 15\n",
        "cfg.runner = dict(type='EpochBasedRunner', max_epochs=cfg.max_epochs)\n",
        "\n",
        "# We can also use tensorboard to log the training process\n",
        "cfg.log_config.hooks = [\n",
        "    dict(type='TextLoggerHook'),\n",
        "    dict(type='TensorboardLoggerHook')]\n",
        "\n",
        "# TODO?\n",
        "# cfg.workflow = [('train', 1), ('val', 1)]\n",
        "\n",
        "cfg.pop(\"train_dataset\")\n",
        "cfg.pop(\"train_pipeline\")\n",
        "cfg.pop(\"test_pipeline\")\n",
        "\n",
        "# Tried this but it didn't help with the mmdetection's concat problem\n",
        "# cfg.data.train.dataset[\"filter_empty_gt\"] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config:\n",
            "optimizer = dict(\n",
            "    type='SGD',\n",
            "    lr=0.01,\n",
            "    momentum=0.9,\n",
            "    weight_decay=0.0005,\n",
            "    nesterov=True,\n",
            "    paramwise_cfg=dict(norm_decay_mult=0.0, bias_decay_mult=0.0))\n",
            "optimizer_config = dict(grad_clip=None)\n",
            "lr_config = dict(\n",
            "    policy='YOLOX',\n",
            "    warmup=None,\n",
            "    by_epoch=False,\n",
            "    warmup_by_epoch=True,\n",
            "    warmup_ratio=1,\n",
            "    warmup_iters=5,\n",
            "    num_last_epochs=15,\n",
            "    min_lr_ratio=0.05)\n",
            "runner = dict(type='EpochBasedRunner', max_epochs=15)\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(\n",
            "    interval=50,\n",
            "    hooks=[dict(type='TextLoggerHook'),\n",
            "           dict(type='TensorboardLoggerHook')])\n",
            "custom_hooks = [\n",
            "    dict(type='YOLOXModeSwitchHook', num_last_epochs=15, priority=48),\n",
            "    dict(type='SyncNormHook', num_last_epochs=15, interval=10, priority=48),\n",
            "    dict(\n",
            "        type='ExpMomentumEMAHook',\n",
            "        resume_from=None,\n",
            "        momentum=0.0001,\n",
            "        priority=49)\n",
            "]\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = '/home/tedro/Desktop/d_projekty/bp/proj/../mmdetection/checkpoints/yolox_s_8x8_300e_coco_20211121_095711-4592a793.pth'\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "opencv_num_threads = 0\n",
            "mp_start_method = 'fork'\n",
            "auto_scale_lr = dict(enable=False, base_batch_size=64)\n",
            "img_scale = (640, 640)\n",
            "model = dict(\n",
            "    type='YOLOX',\n",
            "    input_size=(640, 640),\n",
            "    random_size_range=(15, 25),\n",
            "    random_size_interval=10,\n",
            "    backbone=dict(type='CSPDarknet', deepen_factor=0.33, widen_factor=0.5),\n",
            "    neck=dict(\n",
            "        type='YOLOXPAFPN',\n",
            "        in_channels=[128, 256, 512],\n",
            "        out_channels=128,\n",
            "        num_csp_blocks=1),\n",
            "    bbox_head=dict(\n",
            "        type='YOLOXHead', num_classes=8, in_channels=128, feat_channels=128),\n",
            "    train_cfg=dict(assigner=dict(type='SimOTAAssigner', center_radius=2.5)),\n",
            "    test_cfg=dict(score_thr=0.01, nms=dict(type='nms', iou_threshold=0.65)))\n",
            "data_root = '/home/tedro/Downloads/datasets/'\n",
            "dataset_type = 'CocoDataset'\n",
            "data = dict(\n",
            "    samples_per_gpu=8,\n",
            "    workers_per_gpu=4,\n",
            "    persistent_workers=True,\n",
            "    train=dict(\n",
            "        type='MultiImageMixDataset',\n",
            "        dataset=dict(\n",
            "            type='ClassBalancedDataset',\n",
            "            oversample_thr=0.2,\n",
            "            dataset=dict(\n",
            "                type='CustomDataset',\n",
            "                ann_file='/home/tedro/Downloads/datasets/train.pickle',\n",
            "                img_prefix='/home/tedro/Downloads/datasets/',\n",
            "                pipeline=[\n",
            "                    dict(type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True)\n",
            "                ],\n",
            "                filter_empty_gt=False)),\n",
            "        pipeline=[\n",
            "            dict(type='Mosaic', img_scale=(640, 640), pad_val=114.0),\n",
            "            dict(\n",
            "                type='RandomAffine',\n",
            "                scaling_ratio_range=(0.1, 2),\n",
            "                border=(-320, -320)),\n",
            "            dict(\n",
            "                type='MixUp',\n",
            "                img_scale=(640, 640),\n",
            "                ratio_range=(0.8, 1.6),\n",
            "                pad_val=114.0),\n",
            "            dict(type='YOLOXHSVRandomAug'),\n",
            "            dict(type='RandomFlip', flip_ratio=0.5),\n",
            "            dict(type='Resize', img_scale=(640, 640), keep_ratio=True),\n",
            "            dict(\n",
            "                type='Pad',\n",
            "                pad_to_square=True,\n",
            "                pad_val=dict(img=(114.0, 114.0, 114.0))),\n",
            "            dict(\n",
            "                type='FilterAnnotations',\n",
            "                min_gt_bbox_wh=(1, 1),\n",
            "                keep_empty=False),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='/home/tedro/Downloads/datasets/val.pickle',\n",
            "        img_prefix='/home/tedro/Downloads/datasets/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(640, 640),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Pad',\n",
            "                        pad_to_square=True,\n",
            "                        pad_val=dict(img=(114.0, 114.0, 114.0))),\n",
            "                    dict(type='DefaultFormatBundle'),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='/home/tedro/Downloads/datasets/test.pickle',\n",
            "        img_prefix='/home/tedro/Downloads/datasets/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(640, 640),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Pad',\n",
            "                        pad_to_square=True,\n",
            "                        pad_val=dict(img=(114.0, 114.0, 114.0))),\n",
            "                    dict(type='DefaultFormatBundle'),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "max_epochs = 15\n",
            "num_last_epochs = 15\n",
            "interval = 10\n",
            "evaluation = dict(\n",
            "    save_best='auto', interval=1, dynamic_intervals=[(285, 1)], metric='mAP')\n",
            "work_dir = '/home/tedro/Desktop/d_projekty/bp/proj/working_dir'\n",
            "gpu_ids = [0]\n",
            "device = 'cuda'\n",
            "seed = 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1ZSc7wQWEdLp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-28 13:27:06,126 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
            "2022-11-28 13:27:06,174 - mmdet - INFO - load checkpoint from local path: /home/tedro/Desktop/d_projekty/bp/proj/../mmdetection/checkpoints/yolox_s_8x8_300e_coco_20211121_095711-4592a793.pth\n",
            "2022-11-28 13:27:06,334 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for bbox_head.multi_level_conv_cls.0.weight: copying a param with shape torch.Size([80, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([8, 128, 1, 1]).\n",
            "size mismatch for bbox_head.multi_level_conv_cls.0.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([8]).\n",
            "size mismatch for bbox_head.multi_level_conv_cls.1.weight: copying a param with shape torch.Size([80, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([8, 128, 1, 1]).\n",
            "size mismatch for bbox_head.multi_level_conv_cls.1.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([8]).\n",
            "size mismatch for bbox_head.multi_level_conv_cls.2.weight: copying a param with shape torch.Size([80, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([8, 128, 1, 1]).\n",
            "size mismatch for bbox_head.multi_level_conv_cls.2.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([8]).\n",
            "2022-11-28 13:27:06,337 - mmdet - INFO - Start running, host: tedro@debian, work_dir: /home/tedro/Desktop/d_projekty/bp/proj/working_dir\n",
            "2022-11-28 13:27:06,340 - mmdet - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) YOLOXLrUpdaterHook                 \n",
            "(49          ) ExpMomentumEMAHook                 \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) YOLOXLrUpdaterHook                 \n",
            "(48          ) YOLOXModeSwitchHook                \n",
            "(48          ) SyncNormHook                       \n",
            "(49          ) ExpMomentumEMAHook                 \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) YOLOXLrUpdaterHook                 \n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(ABOVE_NORMAL) OptimizerHook                      \n",
            "(49          ) ExpMomentumEMAHook                 \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(48          ) SyncNormHook                       \n",
            "(49          ) ExpMomentumEMAHook                 \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "after_run:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "2022-11-28 13:27:06,342 - mmdet - INFO - workflow: [('train', 1)], max: 15 epochs\n",
            "2022-11-28 13:27:06,392 - mmdet - INFO - Checkpoints will be saved to /home/tedro/Desktop/d_projekty/bp/proj/working_dir by HardDiskBackend.\n",
            "/home/tedro/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "2022-11-28 13:27:36,868 - mmdet - INFO - Epoch [1][50/12284]\tlr: 5.000e-04, eta: 1 day, 7:01:26, time: 0.606, data_time: 0.118, memory: 4482, loss_cls: 1.6529, loss_bbox: 2.1895, loss_obj: 2.8442, loss: 6.6865\n",
            "2022-11-28 13:28:01,503 - mmdet - INFO - Epoch [1][100/12284]\tlr: 5.000e-04, eta: 1 day, 4:06:27, time: 0.493, data_time: 0.050, memory: 5319, loss_cls: 1.1783, loss_bbox: 2.1278, loss_obj: 2.4153, loss: 5.7214\n"
          ]
        }
      ],
      "source": [
        "# https://colab.research.google.com/github/ZwwWayne/mmdetection/blob/update-colab/demo/MMDet_Tutorial.ipynb#scrollTo=hamZrlnH-YDD\n",
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "\n",
        "# cfg.model.CLASSES = classes\n",
        "\n",
        "# Build dataset\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "\n",
        "# TODO does this help with \"Class names are not saved in the checkpoint\"?\n",
        "# cfg.model.CLASSES = datasets[0].CLASSES\n",
        " \n",
        "# Build the detector\n",
        "model = build_detector(cfg.model)\n",
        "\n",
        "# Train\n",
        "model.CLASSES = datasets[0].CLASSES\n",
        "train_detector(model, datasets, cfg)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
