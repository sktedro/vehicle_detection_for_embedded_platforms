{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We need older numpy version, otherwise an error occurs (newer numpy has no member \"int\", \"float\",...)\n",
        "# TODO testing lower version of openmim - 0.3.2 is on dell 7400 (was 0.3.5) - did not work\n",
        "%pip install opencv-python numpy==1.23.5 openmim torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPbCuq5wWL38",
        "outputId": "6f5aad38-9292-4381-a9ed-d9f9cdeab69b"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import cv2\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import pickle\n",
        "import traceback\n",
        "\n",
        "# Classes are defined in process_dataset/common.py\n",
        "from process_dataset.common import classes, classes_dict, datasets_path, dataset_pickle_filepath"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Additional paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwfR63Ryv1y2",
        "outputId": "2565aac0-e2fd-4e65-e546-2273187453a3"
      },
      "outputs": [],
      "source": [
        "import paths\n",
        "\n",
        "with open(\"./paths.py\") as f:\n",
        "    print(f.read())\n",
        "\n",
        "# proj_path = os.getcwd()\n",
        "\n",
        "# drive_dirpath = os.path.join(proj_path, \"drive\")\n",
        "# drive_traffic_cams_path = os.path.join(drive_dirpath, \"traffic_cams\")\n",
        "\n",
        "# mmdetection_path = os.path.join(proj_path, \"..\", \"mmdetection\")\n",
        "\n",
        "# working_dirpath = os.path.join(proj_path, \"working_dir\")\n",
        "\n",
        "# process_dataset_dirpath = os.path.join(proj_path, \"process_dataset\")\n",
        "\n",
        "# !mkdir -p $working_dirpath\n",
        "\n",
        "# ! Do this in a separate terminal:\n",
        "# !mkdir -p $drive_dirpath\n",
        "# !rclone mount remote: $drive_dirpath\n",
        "\n",
        "# Don't forget to unmount when you're finished\n",
        "\n",
        "# TODO assert everything is in the right place"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkjCldfKpI-O"
      },
      "source": [
        "# Installing mmdetection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzbBwCKrpUQh",
        "outputId": "8f83fd26-9409-4ea9-e167-4a56efa7f260"
      },
      "outputs": [],
      "source": [
        "# We install older mmcv version, otherwise error occurs (mmdet says newest possible is 1.7.0)\n",
        "!mim install mmcv-full==1.7.0\n",
        "%cd $paths.mmdetection_path/..\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd mmdetection\n",
        "%pip install -e .\n",
        "%cd $paths.proj_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTcJbMQ6rfrY",
        "outputId": "116dfc55-23bf-4c06-e7a5-140a494ec630"
      },
      "outputs": [],
      "source": [
        "#@title Verify installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1vbw2orvzmF",
        "outputId": "c2ad7f29-47e0-48f1-d452-f6f1018215b3"
      },
      "outputs": [],
      "source": [
        "from mmcv import collect_env\n",
        "try:\n",
        "    collect_env() # TODO throws error\n",
        "except Exception as e:\n",
        "    print(\"Could not run 'collect_env()'. Exception:\")\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXZZKxllra7-"
      },
      "source": [
        "# Download YOLOX-s config and checkpoint (pre-trained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmd-1lfprZKZ",
        "outputId": "a1a7c23d-742f-4d5f-e274-4d743494804a"
      },
      "outputs": [],
      "source": [
        "# TODO don't download it here. Leave it to the user\n",
        "# Memory requirements for YOLOX models: \n",
        "# YOLOX-s\t7.6 GB\n",
        "# YOLOX-l\t19.9 GB\n",
        "# YOLOX-x\t28.1 GB\n",
        "\n",
        "# url = \"https://download.openmmlab.com/mmdetection/v2.0/yolox/yolox_x_8x8_300e_coco/\" + model_checkpoint_filename\n",
        "# url = \"https://download.openmmlab.com/mmdetection/v2.0/yolox/yolox_s_8x8_300e_coco/\" + paths.model_checkpoint_filename\n",
        "# !wget -c $url -O $paths.model_checkpoint_filepath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egmFK4r_CiHB"
      },
      "outputs": [],
      "source": [
        "# https://colab.research.google.com/github/ZwwWayne/mmdetection/blob/update-colab/demo/MMDet_Tutorial.ipynb#scrollTo=hamZrlnH-YDD\n",
        "from mmdet.apis import set_random_seed\n",
        "from mmcv import Config\n",
        "\n",
        "cfg = Config.fromfile(paths.model_config_filepath)\n",
        "\n",
        "# print(f'Initial config:\\n{cfg.pretty_text}')\n",
        "\n",
        "if paths.last_checkpoint_filepath:\n",
        "    cfg.resume_from = paths.last_checkpoint_filepath\n",
        "else:\n",
        "    cfg.load_from = paths.model_checkpoint_filepath\n",
        "\n",
        "cfg.work_dir = paths.working_dirpath\n",
        "\n",
        "cfg.data_root = datasets_path\n",
        "\n",
        "img_prefix = datasets_path\n",
        "\n",
        "# dataset_filepath = os.path.join(dataset_mio_tcd_path, \"gt.pickle\")\n",
        "dataset_filepath = os.path.join(datasets_path, \"dataset.pickle\")\n",
        "train_filepath = os.path.join(datasets_path, \"train.pickle\")\n",
        "val_filepath = os.path.join(datasets_path, \"val.pickle\")\n",
        "test_filepath = os.path.join(datasets_path, \"test.pickle\")\n",
        "\n",
        "cfg.data.train.dataset.type = \"CustomDataset\"\n",
        "cfg.data.train.dataset.ann_file = train_filepath\n",
        "cfg.data.train.dataset.img_prefix = img_prefix\n",
        "cfg.data.val.type = \"CustomDataset\"\n",
        "cfg.data.val.ann_file = val_filepath\n",
        "cfg.data.val.img_prefix = img_prefix\n",
        "cfg.data.test.type = \"CustomDataset\"\n",
        "cfg.data.test.ann_file = test_filepath\n",
        "cfg.data.test.img_prefix = img_prefix\n",
        "\n",
        "cfg.data.train.dataset = {\n",
        "    \"type\": 'ClassBalancedDataset',\n",
        "    # \"oversample_thr\": 1e-3,\n",
        "    # \"oversample_thr\": 0.01,\n",
        "    \"oversample_thr\": 0.1,\n",
        "    \"dataset\": cfg.data.train.dataset\n",
        "}\n",
        "\n",
        "\"\"\"\n",
        "img_norm_cfg = {\n",
        "    # \"mean\": [103.530, 116.280, 123.675], # Taken from yolof\n",
        "    \"mean\": [114.0, 114.0, 114.0], \n",
        "    \"std\": [1.0, 1.0, 1.0], \n",
        "    \"to_rgb\": False\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "cfg.train_pipeline = [\n",
        "    # dict(type='Mosaic', # Not really useful here\n",
        "    #      img_scale=cfg.img_scale, \n",
        "    #      pad_val=114.0),\n",
        "    dict(type='RandomAffine',\n",
        "        # min_bbox_size=8, # No need. Done in FilterAnnotations\n",
        "        # border=(-cfg.img_scale[0] // 2, -cfg.img_scale[1] // 2), # This was the problem. No idea why I added it. Shouldn't exist\n",
        "        scaling_ratio_range=(0.1, 2),\n",
        "        max_rotate_degree=15,\n",
        "        max_shear_degree=10),\n",
        "    # dict(type='MixUp', # Not really useful here\n",
        "    #     img_scale=cfg.img_scale,\n",
        "    #     ratio_range=(0.8, 1.6),\n",
        "    #     pad_val=114.0),\n",
        "    dict(type='YOLOXHSVRandomAug'),\n",
        "    dict(type='RandomFlip',\n",
        "         flip_ratio=0.5,\n",
        "         direction=\"horizontal\"), # (horizontal is implicit)\n",
        "    # According to the official implementation, multi-scale\n",
        "    # training is not considered here but in the\n",
        "    # 'mmdet/models/detectors/yolox.py'.\n",
        "    # TODO RandomCrop?\n",
        "    dict(type='Resize',\n",
        "         img_scale=cfg.img_scale,\n",
        "         keep_ratio=True),\n",
        "    dict(type='Pad',\n",
        "        pad_to_square=True,\n",
        "        # If the image is three-channel, the pad value needs\n",
        "        # to be set separately for each channel.\n",
        "        pad_val=dict(img=(114.0, 114.0, 114.0))),\n",
        "    dict(type='FilterAnnotations',\n",
        "        # min_gt_bbox_wh=(8, 8), # TODO Should be okay but I can try increasing\n",
        "        min_gt_bbox_wh=(16, 16),\n",
        "        keep_empty=False),\n",
        "    dict(type=\"PhotoMetricDistortion\"),\n",
        "    # Is this OK? Heard that YOLOX does not need normalization or something...\n",
        "    # Nope, it definitely does not. I tried one epoch with and one without, and\n",
        "    # the results (loss plots) were actually the same\n",
        "    # dict(type='Normalize', **img_norm_cfg), # img_norm_cfg taken from yolof\n",
        "    dict(type='DefaultFormatBundle'),\n",
        "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
        "]\n",
        "cfg.train_dataset.pipeline = cfg.train_pipeline\n",
        "cfg.data.train.pipeline = cfg.train_pipeline\n",
        "\n",
        "cfg.gpu_ids = [0]\n",
        "cfg.device = \"cuda\"\n",
        "\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "\n",
        "# The original learning rate (LR) is set for 8-GPU training.\n",
        "# We divide it by 8 since we only use one GPU.\n",
        "# cfg.optimizer.lr = 0.02 # This instead of 0.02 / 8 - nope, that's too much\n",
        "cfg.optimizer.lr /= 8 # 0.00125\n",
        "# cfg.optimizer.lr = 0.001\n",
        "# cfg.optimizer.lr = 0.0001 # bak4\n",
        "\n",
        "# Batch size (default 8)\n",
        "# cfg.data.samples_per_gpu = 32 # Let's try 32 - nope, cuda out of memory on 7400\n",
        "# cfg.data.samples_per_gpu = 16 # nope, cuda out of memory on 7400\n",
        "# cfg.data.samples_per_gpu = 12 # This seems to work (11111 of 11178MiB used) - not on P52\n",
        "cfg.data.samples_per_gpu = 11 # Works on P52\n",
        "# cfg.data.samples_per_gpu = 10\n",
        "\n",
        "# Workers per gpu (default 4)\n",
        "# Tested 8, 12 and 16 on P52 and higher numbers actually made the training (ETA) longer\n",
        "# With 12, ETA was about 10% longer than at default. Using 2, speed is slightly improved (~2%)\n",
        "# cfg.data.workers_per_gpu = 8 # Doesn't seem to do much\n",
        "\n",
        "# Orig yolox-s config says: USER SHOULD NOT CHANGE ITS VALUES\n",
        "# ! But that, hopefully, means that user should not change LR, but can change\n",
        "# the auto_scale_lr setting...\n",
        "# cfg.auto_scale_lr = {}\n",
        "cfg.auto_scale_lr = {\n",
        "    \"enable\": True, \n",
        "    \"base_batch_size\": cfg.data.samples_per_gpu\n",
        "    }\n",
        "\n",
        "# Reduce the lr warmup to one epoch (instead of 5)\n",
        "# cfg.lr_config.warmup_iters = 1\n",
        "# cfg.lr_config.warmup = None\n",
        "\n",
        "# cfg.log_config.interval = 100\n",
        "cfg.log_config.interval = 50\n",
        "\n",
        "# Change the evaluation metric since we use customized dataset.\n",
        "cfg.evaluation.metric = 'mAP'\n",
        "\n",
        "# We can set the evaluation interval to reduce the evaluation times\n",
        "cfg.evaluation.interval = 1\n",
        "\n",
        "# We can set the checkpoint saving interval to reduce the storage cost\n",
        "cfg.checkpoint_config.interval = 1\n",
        "\n",
        "cfg.max_epochs = 300\n",
        "cfg.runner = dict(type='EpochBasedRunner', max_epochs=cfg.max_epochs)\n",
        "\n",
        "# We can also use tensorboard to log the training process\n",
        "cfg.log_config.hooks = [\n",
        "    dict(type='TextLoggerHook'),\n",
        "    dict(type='TensorboardLoggerHook')]\n",
        "\n",
        "# TODO validation sometimes\n",
        "# cfg.workflow = [('train', 1), ('val', 1)]\n",
        "\n",
        "cfg.pop(\"train_dataset\")\n",
        "cfg.pop(\"train_pipeline\")\n",
        "cfg.pop(\"test_pipeline\")\n",
        "\n",
        "# Set number of classes\n",
        "cfg.model.bbox_head.num_classes = len(classes)\n",
        "\n",
        "# Tried this but it didn't help with the mmdetection's concat problem\n",
        "# cfg.data.train.dataset[\"filter_empty_gt\"] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZSc7wQWEdLp"
      },
      "outputs": [],
      "source": [
        "# https://colab.research.google.com/github/ZwwWayne/mmdetection/blob/update-colab/demo/MMDet_Tutorial.ipynb#scrollTo=hamZrlnH-YDD\n",
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "\n",
        "# Build dataset\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        " \n",
        "# Build the detector\n",
        "# model = build_detector(cfg.model, test_cfg=cfg.data.test)\n",
        "model = build_detector(cfg.model)\n",
        "\n",
        "# Train\n",
        "model.CLASSES = classes\n",
        "train_detector(model, datasets, cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from mmdet.apis import single_gpu_test\n",
        "# from mmdet.datasets import build_dataloader, build_dataset\n",
        "# from mmdet.utils import build_dp\n",
        "\n",
        "# data_loader = build_dataloader(build_dataset(cfg.data.test), samples_per_gpu=64, workers_per_gpu=1)\n",
        "# dp = build_dp(model, cfg.device, device_ids=cfg.gpu_ids)\n",
        "# outputs = single_gpu_test(dp, data_loader, out_dir=paths.working_dirpath)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "229fedebb1d7394cf57a31acf727fae7ea6323c87170158d2b4890534347897d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
