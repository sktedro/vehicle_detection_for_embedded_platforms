{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We need older numpy version, otherwise an error occurs (newer numpy has no member \"int\", \"float\",...)\n",
        "# %pip install opencv-python numpy==1.23.5 torchvision\n",
        "# %pip install opencv-python numpy torchvision # TODO try this instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzbBwCKrpUQh",
        "outputId": "8f83fd26-9409-4ea9-e167-4a56efa7f260"
      },
      "outputs": [],
      "source": [
        "# %pip install -U openmim\n",
        "# !mim install \"mmengine>=0.3.1\"\n",
        "# !mim install \"mmcv>=2.0.0rc1,<2.1.0\"\n",
        "\n",
        "# !mim install \"mmdet>=3.0.0rc5,<3.1.0\"\n",
        "\n",
        "# We can install mmdet from repository, to which we can make changes\n",
        "# %cd $paths.mmdetection_path/..\n",
        "# !git clone https://github.com/open-mmlab/mmdetection.git\n",
        "# %cd mmdetection\n",
        "# %pip install -e .\n",
        "# %cd $paths.proj_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPbCuq5wWL38",
        "outputId": "6f5aad38-9292-4381-a9ed-d9f9cdeab69b"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "from pprint import pprint\n",
        "from time import time\n",
        "import os\n",
        "import traceback\n",
        "\n",
        "import process_dataset.common as common"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Additional paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwfR63Ryv1y2",
        "outputId": "2565aac0-e2fd-4e65-e546-2273187453a3"
      },
      "outputs": [],
      "source": [
        "import paths\n",
        "\n",
        "# Print paths.py file\n",
        "with open(\"./paths.py\") as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines.copy():\n",
        "        if line.startswith(\"#\"):\n",
        "            lines.remove(line)\n",
        "    print(\"\".join(lines).replace(\"\\n\\n\\n\", \"\\n\"))\n",
        "\n",
        "# Assert everything is in the right place\n",
        "assert os.path.exists(paths.proj_path)\n",
        "assert os.path.exists(paths.process_dataset_dirpath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXZZKxllra7-"
      },
      "source": [
        "# Download YOLOX-s config and checkpoint (pre-trained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmd-1lfprZKZ",
        "outputId": "a1a7c23d-742f-4d5f-e274-4d743494804a"
      },
      "outputs": [],
      "source": [
        "# TODO don't download it here. Leave it to the user\n",
        "# Memory requirements for YOLOX models:\n",
        "# YOLOX-s\t7.6 GB\n",
        "# YOLOX-l\t19.9 GB\n",
        "# YOLOX-x\t28.1 GB\n",
        "\n",
        "# url = \"https://download.openmmlab.com/mmdetection/v2.0/yolox/yolox_x_8x8_300e_coco/\" + model_checkpoint_filename\n",
        "# url = \"https://download.openmmlab.com/mmdetection/v2.0/yolox/yolox_s_8x8_300e_coco/\" + paths.model_checkpoint_filename\n",
        "# !wget -c $url -O $paths.model_checkpoint_filepath\n",
        "\n",
        "assert os.path.exists(paths.model_config_filepath)\n",
        "assert os.path.exists(paths.model_checkpoint_filepath)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egmFK4r_CiHB"
      },
      "outputs": [],
      "source": [
        "# https://colab.research.google.com/github/ZwwWayne/mmdetection/blob/update-colab/demo/MMDet_Tutorial.ipynb#scrollTo=hamZrlnH-YDD\n",
        "# from mmcv import Config\n",
        "from mmengine.config import Config\n",
        "\n",
        "cfg = Config.fromfile(paths.model_config_filepath)\n",
        "\n",
        "# TODO works?\n",
        "if paths.last_checkpoint_filepath:\n",
        "    cfg.load_from = paths.last_checkpoint_filepath\n",
        "    cfg.resume = True\n",
        "else:\n",
        "    cfg.load_from = paths.model_checkpoint_filepath\n",
        "\n",
        "cfg.work_dir = paths.working_dirpath\n",
        "\n",
        "data_root = common.datasets_dirpath\n",
        "cfg.data_root = data_root\n",
        "\n",
        "# Set classes\n",
        "cfg[\"metainfo\"] = dict(\n",
        "    classes = tuple(common.classes_ids.keys())\n",
        ")\n",
        "\n",
        "# Batch size (default 8)\n",
        "# batch_size = 8, # Default\n",
        "# batch_size = 32, # Let's try 32 - nope, cuda out of memory on 7400\n",
        "# batch_size = 16, # nope, cuda out of memory on 7400\n",
        "# batch_size = 12, # This seems to work (11111 of 11178MiB used) - not on P52\n",
        "batch_size = 11 # Works on P52\n",
        "\n",
        "# Workers per gpu (default 4)\n",
        "# Tested 8, 12 and 16 on P52 and higher numbers actually made the training (ETA) longer\n",
        "# With 12, ETA was about 10% longer than at default. Using 2, speed is slightly improved (~2%)\n",
        "# num_workers = 4, # Default\n",
        "# num_workers = 8, # Doesn't seem to do much\n",
        "num_workers = 2\n",
        "\n",
        "# Not needed\n",
        "# img_norm_cfg = {\n",
        "#     # \"mean\": [103.530, 116.280, 123.675], # Taken from yolof\n",
        "#     \"mean\": [114.0, 114.0, 114.0], \n",
        "#     \"std\": [1.0, 1.0, 1.0], \n",
        "#     \"to_rgb\": False\n",
        "# }\n",
        "\n",
        "# Like this, we can use different augmentations for each dataset\n",
        "# + Mosaic? Probably not very useful here\n",
        "# + MixUp? Doesn't seem useful either\n",
        "per_dataset_train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations', with_bbox=True),\n",
        "    dict(type='Resize',\n",
        "        scale=cfg.img_scale,\n",
        "        keep_ratio=True),\n",
        "    dict(type='Pad',\n",
        "        pad_to_square=True,\n",
        "        pad_val=dict(img=(114.0, 114.0, 114.0))),\n",
        "    dict(type='RandomAffine',\n",
        "        # min_bbox_size=8, # No need. Done in FilterAnnotations\n",
        "        # border=(-cfg.img_scale[0] // 2, -cfg.img_scale[1] // 2), # This was a problem. No idea why I added it. Shouldn't exist\n",
        "        scaling_ratio_range=(0, 0), # Needs to be adjusted per dataset later below\n",
        "        max_rotate_degree=10,\n",
        "        max_shear_degree=5),\n",
        "]\n",
        "\n",
        "train_datasets_scaling_ratios = {\n",
        "    \"mio-tcd\"     : (0.7, 1.1),\n",
        "    \"aau\"         : (0.8, 1.1),\n",
        "    \"ndis\"        : (0.9, 3),\n",
        "    \"mtid\"        : (0.9, 2),\n",
        "    \"visdrone_det\": (1.5, 3),\n",
        "    \"detrac\"      : (0.8, 1.2)\n",
        "}\n",
        "\n",
        "train_pipeline = [\n",
        "    dict(type='YOLOXHSVRandomAug'),\n",
        "    dict(type='RandomFlip',\n",
        "         prob=0.5,\n",
        "         direction=\"horizontal\"), # (horizontal is implicit)\n",
        "    dict(type=\"PhotoMetricDistortion\"),\n",
        "    dict(type='FilterAnnotations',\n",
        "        min_gt_bbox_wh=(8, 8), # Should be okay, I think 16x16 causes small objects (even 64x64) to be undetected\n",
        "        keep_empty=False),\n",
        "    #  Is this OK? Heard that YOLOX does not need normalization or something...\n",
        "    #  Nope, it definitely does not. I tried one epoch with and one without, and\n",
        "    #  the results (loss plots) were actually the same\n",
        "    # dict(type='Normalize', **img_norm_cfg), # img_norm_cfg taken from yolof\n",
        "    dict(type=\"PackDetInputs\")\n",
        "]\n",
        "\n",
        "train_datasets_repeats = {\n",
        "    \"mio-tcd\"     : 1,\n",
        "    \"aau\"         : 3, # There are some misannotations so don't make it too frequent\n",
        "    \"ndis\"        : 25,\n",
        "    \"mtid\"        : 6, # It's a video, so already a lot repeats, but it's a great dataset\n",
        "    \"visdrone_det\": 4, # Good dataset, but not very important in this project\n",
        "    \"detrac\"      : 2\n",
        "}\n",
        "\n",
        "train_datasets = []\n",
        "for dataset_name in list(common.datasets.keys()):\n",
        "    ds = dict(\n",
        "        type = \"RepeatDataset\",\n",
        "        times = train_datasets_repeats[dataset_name],\n",
        "        dataset = dict(\n",
        "            type = \"CocoDataset\",\n",
        "            ann_file = os.path.join(common.datasets_dirpath, common.datasets[dataset_name][\"path\"], common.gt_filename),\n",
        "            data_prefix = dict(img=data_root),\n",
        "            data_root = data_root,\n",
        "            pipeline = deepcopy(per_dataset_train_pipeline),\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Set RandomAffine scaling range individually for each dataset\n",
        "    assert ds[\"dataset\"][\"pipeline\"][4][\"type\"] == \"RandomAffine\"\n",
        "    ds[\"dataset\"][\"pipeline\"][4][\"scaling_ratio_range\"] = train_datasets_scaling_ratios[dataset_name]\n",
        "\n",
        "    train_datasets.append(ds)\n",
        "\n",
        "cfg.train_dataloader = dict(\n",
        "    batch_size = batch_size,\n",
        "\n",
        "    num_workers = num_workers,\n",
        "\n",
        "    persistent_workers = True,\n",
        "\n",
        "    sampler=dict(type=\"DefaultSampler\", shuffle=True),\n",
        "\n",
        "    dataset = dict(\n",
        "        # Tried removing MultiImageMixDataset and using ClassBalancedDataset\n",
        "        # directly, but got an error about tensor sizes - MultiImageMixDataset\n",
        "        # is necessary\n",
        "        type = \"MultiImageMixDataset\",\n",
        "\n",
        "        # TODO restore this and use class balanced dataset (was getting an exception when used)\n",
        "        # \"The dataset needs to instantiate self.get_cat_ids() to support ClassBalancedDataset.\"\n",
        "        # So if I have ConcatDataset in ClassBalancedDataset, the ConcatDataset must have get_cat_ids()\n",
        "        # dataset = dict(\n",
        "        #     type = 'ClassBalancedDataset',\n",
        "        #     # oversample_thr = 1e-3, # Default\n",
        "        #     oversample_thr = 0.1, # Seems good\n",
        "        #     dataset = dict(\n",
        "        #         type = \"ConcatDataset\",\n",
        "        #         datasets = train_datasets\n",
        "        #     )\n",
        "        # ),\n",
        "\n",
        "        # This works (omitting class balanced dataset)\n",
        "        dataset = dict(\n",
        "            type = \"ConcatDataset\",\n",
        "            datasets = train_datasets\n",
        "        ),\n",
        "\n",
        "        pipeline = train_pipeline,\n",
        "    ),\n",
        ")\n",
        "\n",
        "cfg.val_dataloader = dict(\n",
        "    batch_size = batch_size,\n",
        "    num_workers = num_workers,\n",
        "    persistent_workers = True,\n",
        "    drop_last = False,\n",
        "    sampler = dict(type=\"DefaultSampler\", shuffle=False),\n",
        "    dataset = dict(\n",
        "        type = \"CocoDataset\",\n",
        "        data_root = data_root,\n",
        "        ann_file = os.path.basename(common.dataset_val_filepath),\n",
        "        data_prefix = dict(img=\"\"),\n",
        "        test_mode = True,\n",
        "        pipeline = cfg.val_dataloader.dataset.pipeline, # Default\n",
        "    )\n",
        ")\n",
        "\n",
        "cfg.test_dataloader = dict(\n",
        "    batch_size = batch_size,\n",
        "    num_workers = num_workers,\n",
        "    persistent_workers = True,\n",
        "    drop_last = False,\n",
        "    sampler = dict(type=\"DefaultSampler\", shuffle=False),\n",
        "    dataset = dict(\n",
        "        type = \"CocoDataset\",\n",
        "        data_root = data_root,\n",
        "        ann_file = os.path.basename(common.dataset_test_filepath),\n",
        "        data_prefix = dict(img=\"\"),\n",
        "        test_mode = True,\n",
        "        pipeline = cfg.test_dataloader.dataset.pipeline, # Default\n",
        "    )\n",
        ")\n",
        "\n",
        "cfg.val_evaluator = dict(\n",
        "    type = \"CocoMetric\",\n",
        "    ann_file = common.dataset_val_filepath,\n",
        "    metric = \"bbox\"\n",
        ")\n",
        "\n",
        "cfg.test_evaluator = dict(\n",
        "    type = \"CocoMetric\",\n",
        "    ann_file = common.dataset_test_filepath,\n",
        "    metric = \"bbox\"\n",
        ")\n",
        "\n",
        "cfg.gpu_ids = [0]\n",
        "cfg.device = \"cuda\"\n",
        "# cfg.device = \"cpu\"\n",
        "\n",
        "cfg.seed = int(time())\n",
        "\n",
        "# The original learning rate (LR) is set for 8-GPU training.\n",
        "# We divide it by 8 since we only use one GPU.\n",
        "# cfg.optimizer.lr = 0.02 # This instead of 0.02 / 8 - nope, that's too much\n",
        "# cfg.optimizer.lr = 0.001 # Not better than 0.00125\n",
        "cfg.optim_wrapper.optimizer.lr /= 8 # 0.00125 # As seen on the internet, seems to be good\n",
        "\n",
        "# Orig yolox-s config says: USER SHOULD NOT CHANGE ITS VALUES\n",
        "# ! But that, hopefully, means that user should not change LR, but can change\n",
        "# the auto_scale_lr setting...\n",
        "# cfg.auto_scale_lr = {}\n",
        "cfg.auto_scale_lr = {\n",
        "    \"enable\": True, \n",
        "    \"base_batch_size\": cfg.train_dataloader.batch_size\n",
        "    }\n",
        "\n",
        "# Set to log every Nth batch\n",
        "for hook_name in list(cfg.default_hooks.keys()):\n",
        "    if cfg.default_hooks[hook_name].type == \"LoggerHook\":\n",
        "        cfg.default_hooks[hook_name].interval = 1\n",
        "\n",
        "# We can set the checkpoint saving interval to reduce the storage cost\n",
        "cfg.default_hooks.checkpoint.interval = 1\n",
        "cfg.default_hooks.checkpoint.max_keep_ckpts = 10\n",
        "\n",
        "cfg.max_epochs = 300\n",
        "\n",
        "# We can also use tensorboard to log the training process\n",
        "cfg.visualizer.vis_backends = [\n",
        "    dict(type='LocalVisBackend'),\n",
        "    dict(type='TensorboardVisBackend')\n",
        "]\n",
        "\n",
        "# TODO validation sometimes?\n",
        "# cfg.workflow = [('train', 1), ('val', 1)]\n",
        "\n",
        "# Removing useless keys so they don't confuse\n",
        "cfg.pop(\"data_root\")\n",
        "cfg.pop(\"dataset_type\")\n",
        "cfg.pop(\"train_pipeline\")\n",
        "cfg.pop(\"train_dataset\")\n",
        "cfg.pop(\"test_pipeline\")\n",
        "cfg.pop(\"max_epochs\")\n",
        "cfg.pop(\"num_last_epochs\")\n",
        "cfg.pop(\"interval\")\n",
        "cfg.pop(\"base_lr\")\n",
        "cfg.pop(\"vis_backends\")\n",
        "\n",
        "# Set number of classes\n",
        "cfg.model.bbox_head.num_classes = len(common.classes_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(cfg.pretty_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZSc7wQWEdLp"
      },
      "outputs": [],
      "source": [
        "# https://colab.research.google.com/github/ZwwWayne/mmdetection/blob/update-colab/demo/MMDet_Tutorial.ipynb#scrollTo=hamZrlnH-YDD\n",
        "from mmengine.runner import Runner\n",
        "\n",
        "try:\n",
        "    runner = Runner.from_cfg(cfg)\n",
        "    runner.train()\n",
        "except:\n",
        "    traceback.print_exc()\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from mmdet.apis import single_gpu_test\n",
        "# from mmdet.datasets import build_dataloader, build_dataset\n",
        "# from mmdet.utils import build_dp\n",
        "\n",
        "# data_loader = build_dataloader(build_dataset(cfg.data.test), samples_per_gpu=64, workers_per_gpu=1)\n",
        "# dp = build_dp(model, cfg.device, device_ids=cfg.gpu_ids)\n",
        "# outputs = single_gpu_test(dp, data_loader, out_dir=paths.working_dirpath)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
